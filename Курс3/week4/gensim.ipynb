{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки gensim для тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая полезная теорема Байеса! :)\n",
    "\n",
    "![comic1](http://imgs.xkcd.com/comics/seashell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"docword.xkcd.txt\", \"vocab.xkcd.txt\")\n",
    "dictionary = data.create_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 27s, sys: 1.19 s, total: 4min 28s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "# обучение модель\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ldamodel.save(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.002*\"wait\" + 0.002*\"sagal\" + 0.002*\"peter\" + 0.001*\"roberts\" + 0.001*\"narrator\" + 0.001*\"elaine\" + 0.001*\"list\" + 0.001*\"dont\" + 0.001*\"mrs\" + 0.001*\"wave\"\n",
      "Topic 1 : 0.005*\"figure\" + 0.002*\"female\" + 0.002*\"text\" + 0.002*\"map\" + 0.002*\"male\" + 0.001*\"island\" + 0.001*\"title\" + 0.001*\"stick\" + 0.001*\"comic\" + 0.001*\"labeled\"\n",
      "Topic 2 : 0.002*\"exhibit\" + 0.001*\"day\" + 0.001*\"paul\" + 0.001*\"ron\" + 0.001*\"man\" + 0.001*\"han\" + 0.001*\"beef\" + 0.001*\"egg\" + 0.001*\"label\" + 0.001*\"text\"\n",
      "Topic 3 : 0.024*\"man\" + 0.012*\"text\" + 0.011*\"person\" + 0.010*\"title\" + 0.010*\"woman\" + 0.009*\"guy\" + 0.007*\"one\" + 0.006*\"girl\" + 0.005*\"just\" + 0.005*\"hat\"\n",
      "Topic 4 : 0.005*\"person\" + 0.003*\"line\" + 0.003*\"text\" + 0.003*\"graph\" + 0.003*\"title\" + 0.002*\"labeled\" + 0.002*\"time\" + 0.002*\"point\" + 0.001*\"number\" + 0.001*\"human\"\n"
     ]
    }
   ],
   "source": [
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print \"Topic\", t, \":\", top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353.90591936\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print 2**(-perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353.90591934423111"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.056803981860081842),\n",
       " (1, 0.056686407043176193),\n",
       " (2, 0.058381399373822598),\n",
       " (3, 0.76433929847377191),\n",
       " (4, 0.063788913249147622)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти люди не знают про тематические модели:\n",
    "\n",
    "![comic2](http://imgs.xkcd.com/comics/the_problem_with_wikipedia.png) | ![comic3](http://imgs.xkcd.com/comics/mystery_news.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
